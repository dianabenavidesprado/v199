---
title: 'Model-Free Generative Replay for Lifelong Reinforcement Learning: Application
  to Starcraft-2'
abstract: 'One approach to meet the challenges of deep lifelong reinforcement learning
  (LRL) is careful management of the agentâ€™s learning experiences, in order to learn
  (without forgetting) and build internal meta-models (of the tasks, environments,
  agents, and world).  Generative replay (GR) is a biologically-inspired replay mechanism
  that augments learning experiences with self-labelled examples drawn from an internal
  generative model that is updated over time. In this paper, we present a version
  of GR for LRL that satisfies two desiderata: (a) Introspective density modelling
  of the latent representations of policies learned using deep RL, and (b) Model-free
  end-to-end learning. The first property avoids the challenges of density modelling
  of complex high-dimensional perceptual inputs, whereas policy learning using deep
  RL works well with such perceptual inputs. The second property avoids the challenges
  of learning temporal dynamics and reward functions from few learning experiences
  with sparse rewards. In this work, we study three deep learning architectures for
  model-free GR, starting from a naive GR and adding ingredients to achieve (a) and
  (b). We evaluate our proposed algorithms on three different scenarios comprising
  tasks from the StarCraft2 and Minigrid domains. We report several key findings showing
  the impact of the design choices on quantitative metrics that include transfer learning,
  generalization to unseen tasks, fast adaptation after task change, performance comparable
  to a task expert, and minimizing catastrophic forgetting.  We observe that our GR
  prevents drift in the features-to-action mapping from the latent vector space of
  a deep actor-critic agent. We also show improvements in established lifelong learning
  metrics. We find that the introduction of a small random replay buffer is needed
  to significantly increase the stability of training, when used in conjunction with
  the replay buffer and the generated replay buffer. Overall, we find that hidden
  replay (a well-known architecture for class-incremental classification) is the most
  promising approach that pushes the state-of-the-art in GR for LRL.'
video: https://youtu.be/o5h5vRn2_3s
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: daniels22a
month: 0
tex_title: 'Model-Free Generative Replay for Lifelong Reinforcement Learning: Application
  to Starcraft-2'
firstpage: 1120
lastpage: 1145
page: 1120-1145
order: 1120
cycles: false
bibtex_author: Daniels, Zachary Alan and Raghavan, Aswin and Hostetler, Jesse and
  Rahman, Abrar and Sur, Indranil and Piacentino, Michael and Divakaran, Ajay and
  Corizzo, Roberto and Faber, Kamil and Japkowicz, Nathalie and Baron, Michael and
  Smith, James and Joshi, Sahana Pramod and Kira, Zsolt and Taylor, Cameron Ethan
  and Gurbuz, Mustafa Burak and Dovrolis, Constantine and Hayes, Tyler L. and Kanan,
  Christopher and Gallardo, Jhair
author:
- given: Zachary Alan
  family: Daniels
- given: Aswin
  family: Raghavan
- given: Jesse
  family: Hostetler
- given: Abrar
  family: Rahman
- given: Indranil
  family: Sur
- given: Michael
  family: Piacentino
- given: Ajay
  family: Divakaran
- given: Roberto
  family: Corizzo
- given: Kamil
  family: Faber
- given: Nathalie
  family: Japkowicz
- given: Michael
  family: Baron
- given: James
  family: Smith
- given: Sahana Pramod
  family: Joshi
- given: Zsolt
  family: Kira
- given: Cameron Ethan
  family: Taylor
- given: Mustafa Burak
  family: Gurbuz
- given: Constantine
  family: Dovrolis
- given: Tyler L.
  family: Hayes
- given: Christopher
  family: Kanan
- given: Jhair
  family: Gallardo
date: 2022-11-29
address:
container-title: Proceedings of The 1st Conference on Lifelong Learning Agents
volume: '199'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 11
  - 29
pdf: https://proceedings.mlr.press/v199/daniels22a/daniels22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
