---
title: Increasing Model Generalizability for Unsupervised Visual Domain Adaptation
abstract: A dominant approach for addressing unsupervised domain adaptation is to
  map data points for the source and the target domains into an embedding space which
  is modeled as the output-space of a shared deep encoder. The encoder is trained
  to make the embedding space domain-agnostic to make a source-trained classifier
  generalizable on the target domain. A secondary mechanism to improve UDA performance
  further is to make the source domain distribution more compact to improve model
  generalizability. We demonstrate that increasing the interclass margins in the embedding
  space can help to develop a UDA algorithm with improved performance. We estimate
  the internally learned multi-modal distribution for the source domain, learned as
  a result of pretraining, and use it to increase the interclass class separation
  in the source domain to reduce the effect of domain shift.   We demonstrate that
  using our approach leads to improved model generalizability on four standard benchmark
  UDA image classification datasets and compares favorably against exiting methods.
video: https://youtu.be/SjxNFO8rK0k
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rostami22a
month: 0
tex_title: Increasing Model Generalizability for Unsupervised Visual Domain Adaptation
firstpage: 281
lastpage: 293
page: 281-293
order: 281
cycles: false
bibtex_author: Rostami, Mohammad
author:
- given: Mohammad
  family: Rostami
date: 2022-11-29
address:
container-title: Proceedings of The 1st Conference on Lifelong Learning Agents
volume: '199'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 11
  - 29
pdf: https://proceedings.mlr.press/v199/rostami22a/rostami22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
